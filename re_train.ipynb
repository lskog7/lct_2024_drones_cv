{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установим необходимые библиотеки\n",
    "try:\n",
    "    from ultralytics import YOLO, checks\n",
    "except:\n",
    "    %pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "model='E:\\Projects\\VSCode\\Python\\Conda\\LCT\\lct_2024_drones_cv\\current_model' should be a *.pt PyTorch model to run this method, but is a different format. PyTorch models can train, val, predict and export, i.e. 'model.train(data=...)', but exported formats like ONNX, TensorRT etc. only support 'predict' and 'val' modes, i.e. 'yolo predict model=yolov8n.onnx'.\nTo run CUDA or MPS inference please pass the device argument directly in your inference command, i.e. 'model.predict(source=..., device=0)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(pretrained_model_path)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Начинаем процесс дообучения\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclassify\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Количество эпох дообучения\u001b[39;49;00m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Размер входного изображения\u001b[39;49;00m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Размер батча\u001b[39;49;00m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Количество потоков для загрузки данных\u001b[39;49;00m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mruns\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Папка для сохранения результатов тренировки\u001b[39;49;00m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myolov8n_finetune\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Название поддиректории для данной тренировки\u001b[39;49;00m\n\u001b[0;32m     21\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# После дообучения сохраняем финальные веса модели\u001b[39;00m\n\u001b[0;32m     24\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mE:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mProjects\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mVSCode\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mPython\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mConda\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mLCT\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mlct_2024_drones_cv\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mcurrent_model\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     26\u001b[0m )\n",
      "File \u001b[1;32me:\\Projects\\VSCode\\Python\\Conda\\.conda\\Lib\\site-packages\\ultralytics\\engine\\model.py:636\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\n\u001b[0;32m    605\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    606\u001b[0m     trainer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    607\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    608\u001b[0m ):\n\u001b[0;32m    609\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    610\u001b[0m \u001b[38;5;124;03m    Trains the model using the specified dataset and training configuration.\u001b[39;00m\n\u001b[0;32m    611\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;124;03m        ModuleNotFoundError: If the HUB SDK is not installed.\u001b[39;00m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 636\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_is_pytorch_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mid:  \u001b[38;5;66;03m# Ultralytics HUB session with loaded model\u001b[39;00m\n\u001b[0;32m    638\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(kwargs):\n",
      "File \u001b[1;32me:\\Projects\\VSCode\\Python\\Conda\\.conda\\Lib\\site-packages\\ultralytics\\engine\\model.py:259\u001b[0m, in \u001b[0;36mModel._check_is_pytorch_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    257\u001b[0m pt_module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, nn\u001b[38;5;241m.\u001b[39mModule)\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (pt_module \u001b[38;5;129;01mor\u001b[39;00m pt_str):\n\u001b[1;32m--> 259\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m should be a *.pt PyTorch model to run this method, but is a different format. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPyTorch models can train, val, predict and export, i.e. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel.train(data=...)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, but exported \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    262\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformats like ONNX, TensorRT etc. only support \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m modes, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    263\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi.e. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myolo predict model=yolov8n.onnx\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTo run CUDA or MPS inference please pass the device \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    264\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margument directly in your inference command, i.e. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel.predict(source=..., device=0)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    265\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: model='E:\\Projects\\VSCode\\Python\\Conda\\LCT\\lct_2024_drones_cv\\current_model' should be a *.pt PyTorch model to run this method, but is a different format. PyTorch models can train, val, predict and export, i.e. 'model.train(data=...)', but exported formats like ONNX, TensorRT etc. only support 'predict' and 'val' modes, i.e. 'yolo predict model=yolov8n.onnx'.\nTo run CUDA or MPS inference please pass the device argument directly in your inference command, i.e. 'model.predict(source=..., device=0)'"
     ]
    }
   ],
   "source": [
    "# Путь к файлу конфигурации и весам предобученной модели\n",
    "pretrained_model_path = (\n",
    "    \"E:\\\\Projects\\\\VSCode\\\\Python\\\\Conda\\\\LCT\\\\lct_2024_drones_cv\\\\current_model\"\n",
    ")\n",
    "# Путь к датасету для дообучения\n",
    "data_path = \"E:\\\\Projects\\\\Data\\\\LCT\\\\subsets\\\\train_subset_2024_06_06_22_02_08\"\n",
    "\n",
    "# Создаем объект модели YOLOv8 Nano\n",
    "model = YOLO(pretrained_model_path)\n",
    "\n",
    "# Начинаем процесс дообучения\n",
    "model.train(\n",
    "    task=\"classify\",\n",
    "    data=data_path,\n",
    "    epochs=32,  # Количество эпох дообучения\n",
    "    imgsz=640,  # Размер входного изображения\n",
    "    batch=32,  # Размер батча\n",
    "    workers=4,  # Количество потоков для загрузки данных\n",
    "    project=\"runs\\\\train\",  # Папка для сохранения результатов тренировки\n",
    "    name=\"yolov8n_finetune\",  # Название поддиректории для данной тренировки\n",
    ")\n",
    "\n",
    "# После дообучения сохраняем финальные веса модели\n",
    "model.save(\n",
    "    \"E:\\\\Projects\\\\VSCode\\\\Python\\\\Conda\\\\LCT\\\\lct_2024_drones_cv\\\\current_model\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
