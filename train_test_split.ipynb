{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Путь к директории с полным датасетом\n",
    "full_dataset = '/path/to/full/dataset'\n",
    "# Путь к директории для подвыборки\n",
    "subset_path = '/path/to/subset/dataset/train'\n",
    "validation_path = '/path/to/subset/dataset/validation'\n",
    "test_path = '/path/to/subset/dataset/test'\n",
    "\n",
    "# Убедимся, что необходимые директории существуют\n",
    "os.makedirs(subset_path, exist_ok=True)\n",
    "os.makedirs(validation_path, exist_ok=True)\n",
    "os.makedirs(test_path, exist_ok=True)\n",
    "\n",
    "# Список всех файлов изображений и аннотаций в датасете\n",
    "image_files = [f for f in os.listdir(full_dataset) if f.endswith('.jpg')]\n",
    "annotation_files = [f for f in os.listdir(full_dataset) if f.endswith('.txt')]\n",
    "\n",
    "# Убедимся, что количество изображений и аннотаций совпадает\n",
    "assert len(image_files) == len(annotation_files), \"Количество изображений и аннотаций должно совпадать\"\n",
    "\n",
    "# Функция для копирования файлов\n",
    "def copy_files(indices, src_path, dst_path):\n",
    "    for idx in indices:\n",
    "        image_file = image_files[idx]\n",
    "        annotation_file = annotation_files[idx]\n",
    "        shutil.copy(os.path.join(src_path, image_file), os.path.join(dst_path, image_file))\n",
    "        shutil.copy(os.path.join(src_path, annotation_file), os.path.join(dst_path, annotation_file))\n",
    "\n",
    "# Выбираем 5000 случайных изображений и соответствующих аннотаций для валидации\n",
    "validation_indices = random.sample(range(len(image_files)), 5000)\n",
    "copy_files(validation_indices, full_dataset, validation_path)\n",
    "\n",
    "# Удаляем файлы, использованные для валидации, из полного набора данных\n",
    "for idx in sorted(validation_indices, reverse=True):\n",
    "    os.remove(os.path.join(full_dataset, image_files[idx]))\n",
    "    os.remove(os.path.join(full_dataset, annotation_files[idx]))\n",
    "\n",
    "# Обновляем списки файлов после удаления\n",
    "image_files = [f for f in os.listdir(full_dataset) if f.endswith('.jpg')]\n",
    "annotation_files = [f for f in os.listdir(full_dataset) if f.endswith('.txt')]\n",
    "\n",
    "# Выбираем 1000 случайных изображений и соответствующих аннотаций для обучения\n",
    "train_indices = random.sample(range(len(image_files)), 1000)\n",
    "copy_files(train_indices, full_dataset, subset_path)\n",
    "\n",
    "# Выбираем 200 случайных изображений и соответствующих аннотаций для теста из валидационной подвыборки\n",
    "validation_image_files = [f for f in os.listdir(validation_path) if f.endswith('.jpg')]\n",
    "validation_annotation_files = [f for f in os.listdir(validation_path) if f.endswith('.txt')]\n",
    "test_indices = random.sample(range(len(validation_image_files)), 200)\n",
    "copy_files(test_indices, validation_path, test_path)\n",
    "\n",
    "print(\"Подвыборки успешно созданы\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
